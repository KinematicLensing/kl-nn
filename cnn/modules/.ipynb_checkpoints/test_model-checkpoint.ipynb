{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748ac49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from astropy.io import fits\n",
    "\n",
    "from networks import ForkCNN\n",
    "from train import train_nn, prepare_dataloader, ddp_setup\n",
    "from dataset import TrainDataset\n",
    "import config\n",
    "\n",
    "fits_dir = '/xdisk/timeifler/wxs0703/kl_nn/fits/'\n",
    "samp_dir = '/xdisk/timeifler/wxs0703/kl_nn/samples/samples.csv'\n",
    "fig_dir = '/xdisk/timeifler/wxs0703/kl_nn/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "827fe39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "save_every = 1\n",
    "nepochs = config.train['epoch_number']\n",
    "batch_size = config.train['batch_size']\n",
    "nfeatures = config.train['feature_number']\n",
    "f_valid = config.train['validation_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb680414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU0] Epoch 0 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 1 Loss: 10.686147253970672 Time: 1:9\n",
      "Epoch 0 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model0\n",
      "[GPU0] Epoch 1 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 2 Loss: 7.4849850336306165 Time: 1:9\n",
      "Epoch 1 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model1\n",
      "[GPU0] Epoch 2 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 3 Loss: 7.066923973809193 Time: 1:9\n",
      "Epoch 2 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model2\n",
      "[GPU0] Epoch 3 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 4 Loss: 7.086151651429059 Time: 1:9\n",
      "Epoch 3 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model3\n",
      "[GPU0] Epoch 4 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 5 Loss: 7.072547193567309 Time: 1:9\n",
      "Epoch 4 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model4\n",
      "[GPU0] Epoch 5 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 6 Loss: 7.087569097488216 Time: 1:9\n",
      "Epoch 5 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model5\n",
      "[GPU0] Epoch 6 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 7 Loss: 7.050207611165409 Time: 1:9\n",
      "Epoch 6 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model6\n",
      "[GPU0] Epoch 7 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 8 Loss: 7.040708793483525 Time: 1:9\n",
      "Epoch 7 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model7\n",
      "[GPU0] Epoch 8 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 9 Loss: 7.0336416017251375 Time: 1:9\n",
      "Epoch 8 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model8\n",
      "[GPU0] Epoch 9 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 10 Loss: 7.095582122149009 Time: 1:9\n",
      "Epoch 9 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model9\n",
      "[GPU0] Epoch 10 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 11 Loss: 7.039050685859952 Time: 1:9\n",
      "Epoch 10 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model10\n",
      "[GPU0] Epoch 11 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 12 Loss: 7.053458024505043 Time: 1:8\n",
      "Epoch 11 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model11\n",
      "[GPU0] Epoch 12 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 13 Loss: 7.015912824474098 Time: 1:8\n",
      "Epoch 12 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model12\n",
      "[GPU0] Epoch 13 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 14 Loss: 7.023985029865031 Time: 1:9\n",
      "Epoch 13 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model13\n",
      "[GPU0] Epoch 14 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 15 Loss: 7.021343349266128 Time: 1:9\n",
      "Epoch 14 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model14\n",
      "[GPU0] Epoch 15 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 16 Loss: 7.023448919471563 Time: 1:8\n",
      "Epoch 15 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model15\n",
      "[GPU0] Epoch 16 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 17 Loss: 7.002749175677796 Time: 1:9\n",
      "Epoch 16 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model16\n",
      "[GPU0] Epoch 17 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 18 Loss: 7.024820424564281 Time: 1:9\n",
      "Epoch 17 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model17\n",
      "[GPU0] Epoch 18 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 19 Loss: 6.974042625763014 Time: 1:8\n",
      "Epoch 18 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model18\n",
      "[GPU0] Epoch 19 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 20 Loss: 7.048911087676781 Time: 1:9\n",
      "Epoch 19 | Training checkpoint saved at /xdisk/timeifler/wxs0703/kl_nn/model/test_model19\n",
      "[GPU1] Epoch 0 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 1 Loss: 10.65916031727798 Time: 1:9\n",
      "[GPU1] Epoch 1 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 2 Loss: 7.471774241535091 Time: 1:9\n",
      "[GPU1] Epoch 2 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 3 Loss: 7.095605051427073 Time: 1:9\n",
      "[GPU1] Epoch 3 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 4 Loss: 7.099648585152212 Time: 1:9\n",
      "[GPU1] Epoch 4 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 5 Loss: 7.052177555538524 Time: 1:9\n",
      "[GPU1] Epoch 5 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 6 Loss: 7.1244545711086555 Time: 1:9\n",
      "[GPU1] Epoch 6 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 7 Loss: 7.032421302721224 Time: 1:9\n",
      "[GPU1] Epoch 7 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 8 Loss: 7.019225259181796 Time: 1:9\n",
      "[GPU1] Epoch 8 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 9 Loss: 7.020929709055076 Time: 1:9\n",
      "[GPU1] Epoch 9 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 10 Loss: 7.0351846223097025 Time: 1:9\n",
      "[GPU1] Epoch 10 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 11 Loss: 7.016935176045989 Time: 1:9\n",
      "[GPU1] Epoch 11 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 12 Loss: 7.014908051761649 Time: 1:8\n",
      "[GPU1] Epoch 12 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 13 Loss: 7.044426063242189 Time: 1:8\n",
      "[GPU1] Epoch 13 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 14 Loss: 7.0303025620359705 Time: 1:9\n",
      "[GPU1] Epoch 14 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 15 Loss: 7.032329791762462 Time: 1:9\n",
      "[GPU1] Epoch 15 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 16 Loss: 7.021156478674626 Time: 1:8\n",
      "[GPU1] Epoch 16 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 17 Loss: 7.052774021541154 Time: 1:9\n",
      "[GPU1] Epoch 17 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 18 Loss: 7.026115475533911 Time: 1:9\n",
      "[GPU1] Epoch 18 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 19 Loss: 7.087210792951658 Time: 1:8\n",
      "[GPU1] Epoch 19 | Batchsize: 250 | Steps: 20\n",
      "[TRAIN] Epoch: 20 Loss: 6.992412664954362 Time: 1:9\n"
     ]
    }
   ],
   "source": [
    "mp.spawn(train_nn, args=(world_size, save_every, epoch_number, batch_size, nfeatures, f_valid), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f966b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': array([[ 0.02313538,  0.0210766 ,  0.02064033,  0.02372254,  0.03048285,\n",
       "          0.03878293,  0.04511973,  0.04667743,  0.04324204,  0.03768145,\n",
       "          0.03454918,  0.03754403,  0.04728865,  0.06074572,  0.07267753,\n",
       "          0.07841017,  0.07642256,  0.06933998,  0.0627351 ,  0.06229354,\n",
       "          0.07078376,  0.08642256,  0.10356048,  0.11544898,  0.11777081,\n",
       "          0.11115884,  0.10134009,  0.09664959,  0.10395403,  0.1248979 ,\n",
       "          0.15440293,  0.18245971],\n",
       "        [ 0.0206091 ,  0.02360409,  0.02981609,  0.03756555,  0.04374541,\n",
       "          0.04555763,  0.04251722,  0.03728874,  0.03452929,  0.03823883,\n",
       "          0.04919751,  0.06412692,  0.07721657,  0.08325333,  0.08062688,\n",
       "          0.07249942,  0.06539696,  0.06586932,  0.07693505,  0.09621122,\n",
       "          0.11681944,  0.13075458,  0.13310602,  0.12498935,  0.11357299,\n",
       "          0.10894934,  0.11916935,  0.14578484,  0.1822092 ,  0.21608242,\n",
       "          0.23507413,  0.23392966],\n",
       "        [ 0.02889736,  0.03581737,  0.0415162 ,  0.04355639,  0.04126687,\n",
       "          0.03681877,  0.03456986,  0.03864986,  0.05015943,  0.06590377,\n",
       "          0.07974289,  0.08597236,  0.0827987 ,  0.07381125,  0.06644912,\n",
       "          0.06815147,  0.08221079,  0.10560287,  0.13010529,  0.14632691,\n",
       "          0.14871114,  0.13894694,  0.12587275,  0.1216129 ,  0.13557443,\n",
       "          0.16914938,  0.21390288,  0.2546388 ,  0.27658603,  0.2739622 ,\n",
       "          0.2562405 ,  0.24903044],\n",
       "        [ 0.03884846,  0.04086205,  0.03936339,  0.03604119,  0.03455158,\n",
       "          0.03874044,  0.05003095,  0.06573203,  0.07984249,  0.08633731,\n",
       "          0.08306982,  0.07375449,  0.06653772,  0.0697182 ,  0.08693531,\n",
       "          0.11457722,  0.14304942,  0.16150294,  0.163721  ,  0.15209071,\n",
       "          0.13737246,  0.13398251,  0.1527864 ,  0.19485222,  0.24949084,\n",
       "          0.29818514,  0.32339543,  0.31886575,  0.29699868,  0.2896234 ,\n",
       "          0.34081158,  0.49342495],\n",
       "        [ 0.03690509,  0.03468099,  0.0341758 ,  0.03851981,  0.04908231,\n",
       "          0.06385617,  0.07759944,  0.08443861,  0.08178859,  0.07297981,\n",
       "          0.06638181,  0.07101156,  0.09103937,  0.12254319,  0.15471686,\n",
       "          0.17524832,  0.17718837,  0.16362238,  0.14737281,  0.14537291,\n",
       "          0.17010441,  0.22223836,  0.2884614 ,  0.34638095,  0.37524337,\n",
       "          0.3683412 ,  0.3417167 ,  0.33473516,  0.40101182,  0.5919018 ,\n",
       "          0.9378055 ,  1.4337035 ],\n",
       "        [ 0.03314307,  0.0377674 ,  0.04759562,  0.06093755,  0.07356825,\n",
       "          0.08046957,  0.07897927,  0.07161511,  0.06613925,  0.07179631,\n",
       "          0.09347522,  0.12754197,  0.16249664,  0.18472996,  0.18644384,\n",
       "          0.17126507,  0.15406193,  0.15440337,  0.18647766,  0.25043675,\n",
       "          0.3299562 ,  0.3982653 ,  0.4310694 ,  0.42134976,  0.38955483,\n",
       "          0.38393623,  0.4693105 ,  0.7069816 ,  1.132201  ,  1.7369534 ,\n",
       "          2.464434  ,  3.2177987 ],\n",
       "        [ 0.04548113,  0.05747326,  0.0686468 ,  0.07503185,  0.0745814 ,\n",
       "          0.06926663,  0.06555695,  0.07191794,  0.09368153,  0.1282364 ,\n",
       "          0.16444468,  0.18794334,  0.18989268,  0.17391808,  0.15654533,\n",
       "          0.15996316,  0.2002903 ,  0.27732223,  0.37159115,  0.45151907,\n",
       "          0.48881292,  0.47609174,  0.43893757,  0.43603468,  0.54534847,\n",
       "          0.83975416,  1.3599597 ,  2.094157  ,  2.9719355 ,  3.8753645 ,\n",
       "          4.664534  ,  5.2101893 ],\n",
       "        [ 0.06336005,  0.0690427 ,  0.06910349,  0.06559089,  0.06398372,\n",
       "          0.0712426 ,  0.09210539,  0.12499084,  0.16040877,  0.18459381,\n",
       "          0.18785374,  0.17284833,  0.15662913,  0.16355637,  0.21198592,\n",
       "          0.30191472,  0.41102144,  0.5027918 ,  0.5446451 ,  0.52884054,\n",
       "          0.486739  ,  0.48880243,  0.6279251 ,  0.99024063,  1.6227964 ,\n",
       "          2.509382  ,  3.563588  ,  4.642623  ,  5.5784907 ,  6.2173853 ,\n",
       "          6.455708  ,  6.2625957 ],\n",
       "        [ 0.06332298,  0.06105925,  0.06105571,  0.06921576,  0.0891531 ,\n",
       "          0.11930655,  0.15192491,  0.1754136 ,  0.18062222,  0.16876411,\n",
       "          0.15542994,  0.16557217,  0.21990064,  0.3200197 ,  0.44215184,\n",
       "          0.5453374 ,  0.59231305,  0.5743769 ,  0.52867633,  0.538549  ,\n",
       "          0.71383554,  1.15603   ,  1.919618  ,  2.9833367 ,  4.2423015 ,\n",
       "          5.525009  ,  6.6309013 ,  7.377538  ,  7.643563  ,  7.3952847 ,\n",
       "          6.6901703 ,  5.6578875 ],\n",
       "        [ 0.05732766,  0.06577936,  0.08460135,  0.11207074,  0.14123884,\n",
       "          0.16252168,  0.1687552 ,  0.16103096,  0.15241751,  0.16554722,\n",
       "          0.22176163,  0.3256335 ,  0.45507318,  0.56693864,  0.61944133,\n",
       "          0.60177535,  0.555939  ,  0.5783465 ,  0.7971504 ,  1.3311425 ,\n",
       "          2.2438743 ,  3.5093744 ,  5.0025363 ,  6.519214  ,  7.8211637 ,\n",
       "          8.692616  ,  8.991517  ,  8.680725  ,  7.831503  ,  6.600347  ,\n",
       "          5.1877313 ,  3.7915516 ],\n",
       "        [ 0.07887087,  0.10345819,  0.12933467,  0.14822984,  0.15440354,\n",
       "          0.14973912,  0.14608622,  0.1627368 ,  0.21835855,  0.3188267 ,\n",
       "          0.44662556,  0.5615464 ,  0.6197237 ,  0.6063254 ,  0.5646794 ,\n",
       "          0.6027134 ,  0.86843425,  1.5013589 ,  2.577306  ,  4.066748  ,\n",
       "          5.8227334 ,  7.604608  ,  9.131427  , 10.148968  , 10.490411  ,\n",
       "         10.113482  ,  9.104572  ,  7.6507254 ,  5.9899893 ,  4.3559227 ,\n",
       "          2.9315345 ,  1.8229129 ],\n",
       "        [ 0.1167585 ,  0.13330814,  0.13934341,  0.13685738,  0.13666847,\n",
       "          0.15590674,  0.21031022,  0.30418825,  0.4227982 ,  0.5324902 ,\n",
       "          0.593984  ,  0.59034264,  0.5602644 ,  0.61549413,  0.9224095 ,\n",
       "          1.6468928 ,  2.8846161 ,  4.607485  ,  6.647794  ,  8.725561  ,\n",
       "         10.510908  , 11.703592  , 12.106073  , 11.668201  , 10.491846  ,\n",
       "          8.797424  ,  6.8651958 ,  4.969515  ,  3.3241243 ,  2.0511944 ,\n",
       "          1.1779867 ,  0.6563128 ],\n",
       "        [ 0.12415991,  0.12342429,  0.1258653 ,  0.14615887,  0.19776233,\n",
       "          0.2839781 ,  0.39120254,  0.4902115 ,  0.54875195,  0.55436206,\n",
       "          0.5421022 ,  0.61591494,  0.9453726 ,  1.7218897 ,  3.0794902 ,\n",
       "          5.014335  ,  7.34747   ,  9.753383  , 11.841188  , 13.254307  ,\n",
       "         13.756437  , 13.283245  , 11.949321  , 10.010408  ,  7.7938733 ,\n",
       "          5.620194  ,  3.7383459 ,  2.289657  ,  1.3040109 ,  0.7230064 ,\n",
       "          0.43828556,  0.33117375],\n",
       "        [ 0.11430413,  0.1348617 ,  0.18275502,  0.26016772,  0.35513097,\n",
       "          0.4425519 ,  0.49531522,  0.5052996 ,  0.5079558 ,  0.5997752 ,\n",
       "          0.93778044,  1.71178   ,  3.0842116 ,  5.1066313 ,  7.646675  ,\n",
       "         10.373654  , 12.82964   , 14.5625725 , 15.259551  , 14.824462  ,\n",
       "         13.382384  , 11.226852  ,  8.736333  ,  6.283676  ,  4.159951  ,\n",
       "          2.5303798 ,  1.429522  ,  0.78908205,  0.48307997,  0.37418196,\n",
       "          0.3488067 ,  0.33462054],\n",
       "        [ 0.166463  ,  0.23507522,  0.31780207,  0.39328775,  0.43961233,\n",
       "          0.45218787,  0.4651554 ,  0.5675871 ,  0.9034248 ,  1.6472452 ,\n",
       "          2.9561963 ,  4.9065228 ,  7.4293513 , 10.269485  , 12.999841  ,\n",
       "         15.114047  , 16.178797  , 15.980003  , 14.588791  , 12.319597  ,\n",
       "          9.614479  ,  6.9146934 ,  4.564186  ,  2.7600088 ,  1.5474293 ,\n",
       "          0.8510248 ,  0.5272513 ,  0.41946453,  0.3990647 ,  0.38536128,\n",
       "          0.34552744,  0.28117278],\n",
       "        [ 0.28117278,  0.34552744,  0.38536128,  0.3990647 ,  0.41946453,\n",
       "          0.5272513 ,  0.8510248 ,  1.5474293 ,  2.7600088 ,  4.564186  ,\n",
       "          6.9146934 ,  9.614479  , 12.319597  , 14.588791  , 15.980003  ,\n",
       "         16.178797  , 15.114047  , 12.999841  , 10.269485  ,  7.4293513 ,\n",
       "          4.9065228 ,  2.9561963 ,  1.6472452 ,  0.90342486,  0.56758714,\n",
       "          0.46515542,  0.4521879 ,  0.43961233,  0.39328775,  0.3178021 ,\n",
       "          0.23507524,  0.166463  ],\n",
       "        [ 0.3346205 ,  0.3488067 ,  0.37418193,  0.48307994,  0.78908205,\n",
       "          1.429522  ,  2.5303798 ,  4.159951  ,  6.283676  ,  8.736333  ,\n",
       "         11.226852  , 13.382384  , 14.824462  , 15.259551  , 14.5625725 ,\n",
       "         12.82964   , 10.373654  ,  7.646675  ,  5.1066313 ,  3.0842116 ,\n",
       "          1.7117801 ,  0.9377805 ,  0.5997752 ,  0.50795585,  0.5052996 ,\n",
       "          0.49531525,  0.4425519 ,  0.35513097,  0.26016772,  0.18275502,\n",
       "          0.1348617 ,  0.11430412],\n",
       "        [ 0.33117372,  0.43828553,  0.7230064 ,  1.3040109 ,  2.289657  ,\n",
       "          3.7383459 ,  5.620194  ,  7.7938733 , 10.010408  , 11.949321  ,\n",
       "         13.283245  , 13.756437  , 13.254307  , 11.841188  ,  9.753383  ,\n",
       "          7.34747   ,  5.014335  ,  3.0794902 ,  1.7218897 ,  0.94537264,\n",
       "          0.615915  ,  0.5421022 ,  0.5543621 ,  0.54875195,  0.49021152,\n",
       "          0.39120257,  0.2839781 ,  0.19776233,  0.14615887,  0.12586528,\n",
       "          0.12342427,  0.12415988],\n",
       "        [ 0.6563128 ,  1.1779867 ,  2.0511944 ,  3.3241243 ,  4.969515  ,\n",
       "          6.8651958 ,  8.797424  , 10.491846  , 11.668201  , 12.106073  ,\n",
       "         11.703592  , 10.510908  ,  8.725561  ,  6.647794  ,  4.607485  ,\n",
       "          2.8846164 ,  1.6468928 ,  0.92240953,  0.6154942 ,  0.5602644 ,\n",
       "          0.59034264,  0.593984  ,  0.5324902 ,  0.42279822,  0.30418825,\n",
       "          0.21031022,  0.15590674,  0.13666846,  0.13685736,  0.1393434 ,\n",
       "          0.13330811,  0.11675846],\n",
       "        [ 1.8229129 ,  2.9315345 ,  4.3559227 ,  5.9899893 ,  7.6507254 ,\n",
       "          9.104572  , 10.113482  , 10.490411  , 10.148968  ,  9.131427  ,\n",
       "          7.604608  ,  5.8227334 ,  4.066748  ,  2.577306  ,  1.501359  ,\n",
       "          0.8684343 ,  0.6027134 ,  0.56467944,  0.6063254 ,  0.6197237 ,\n",
       "          0.5615464 ,  0.4466256 ,  0.31882674,  0.21835856,  0.1627368 ,\n",
       "          0.14608622,  0.1497391 ,  0.15440351,  0.14822981,  0.12933463,\n",
       "          0.10345816,  0.07887085],\n",
       "        [ 3.7915516 ,  5.1877313 ,  6.600347  ,  7.831503  ,  8.680725  ,\n",
       "          8.991517  ,  8.692616  ,  7.8211637 ,  6.519214  ,  5.0025363 ,\n",
       "          3.5093744 ,  2.2438745 ,  1.3311427 ,  0.7971504 ,  0.57834655,\n",
       "          0.5559391 ,  0.6017754 ,  0.6194414 ,  0.56693864,  0.4550732 ,\n",
       "          0.32563353,  0.22176164,  0.16554722,  0.15241751,  0.16103095,\n",
       "          0.16875517,  0.16252163,  0.1412388 ,  0.11207071,  0.08460133,\n",
       "          0.06577934,  0.05732766],\n",
       "        [ 5.6578875 ,  6.6901703 ,  7.3952847 ,  7.643563  ,  7.377538  ,\n",
       "          6.6309013 ,  5.525009  ,  4.2423015 ,  2.9833367 ,  1.919618  ,\n",
       "          1.15603   ,  0.7138356 ,  0.53854907,  0.52867633,  0.5743769 ,\n",
       "          0.5923131 ,  0.5453374 ,  0.44215187,  0.32001972,  0.21990065,\n",
       "          0.16557218,  0.15542994,  0.1687641 ,  0.18062219,  0.17541355,\n",
       "          0.15192488,  0.11930651,  0.08915307,  0.06921575,  0.06105572,\n",
       "          0.06105927,  0.06332301],\n",
       "        [ 6.2625957 ,  6.455708  ,  6.2173853 ,  5.5784907 ,  4.642623  ,\n",
       "          3.563588  ,  2.509382  ,  1.6227964 ,  0.99024063,  0.62792516,\n",
       "          0.48880246,  0.48673904,  0.52884054,  0.54464513,  0.5027918 ,\n",
       "          0.41102147,  0.30191475,  0.21198595,  0.16355638,  0.15662913,\n",
       "          0.17284833,  0.18785371,  0.18459377,  0.16040872,  0.12499081,\n",
       "          0.09210537,  0.07124259,  0.06398372,  0.06559091,  0.06910352,\n",
       "          0.06904273,  0.0633601 ],\n",
       "        [ 5.2101893 ,  4.664534  ,  3.8753645 ,  2.9719355 ,  2.094157  ,\n",
       "          1.3599597 ,  0.83975416,  0.54534847,  0.4360347 ,  0.4389376 ,\n",
       "          0.47609177,  0.48881295,  0.4515191 ,  0.37159118,  0.27732226,\n",
       "          0.20029032,  0.15996318,  0.15654533,  0.17391807,  0.18989265,\n",
       "          0.1879433 ,  0.16444466,  0.12823635,  0.0936815 ,  0.07191792,\n",
       "          0.06555695,  0.06926665,  0.07458143,  0.0750319 ,  0.06864684,\n",
       "          0.0574733 ,  0.04548116],\n",
       "        [ 3.2177987 ,  2.464434  ,  1.7369534 ,  1.132201  ,  0.7069816 ,\n",
       "          0.4693105 ,  0.38393623,  0.38955486,  0.4213498 ,  0.43106943,\n",
       "          0.39826533,  0.32995623,  0.25043678,  0.18647769,  0.1544034 ,\n",
       "          0.15406193,  0.17126505,  0.18644382,  0.18472993,  0.1624966 ,\n",
       "          0.12754193,  0.09347519,  0.07179629,  0.06613925,  0.07161512,\n",
       "          0.07897931,  0.08046962,  0.07356829,  0.06093759,  0.04759566,\n",
       "          0.03776743,  0.03314308],\n",
       "        [ 1.4337035 ,  0.9378055 ,  0.5919018 ,  0.40101182,  0.33473516,\n",
       "          0.34171674,  0.36834124,  0.3752434 ,  0.34638098,  0.28846142,\n",
       "          0.22223839,  0.17010444,  0.14537293,  0.14737281,  0.16362238,\n",
       "          0.17718834,  0.1752483 ,  0.15471682,  0.12254315,  0.09103934,\n",
       "          0.07101154,  0.06638181,  0.07297983,  0.08178863,  0.08443866,\n",
       "          0.07759949,  0.06385621,  0.04908235,  0.03851984,  0.03417581,\n",
       "          0.03468099,  0.03690507],\n",
       "        [ 0.49342495,  0.34081158,  0.2896234 ,  0.29699868,  0.31886578,\n",
       "          0.32339546,  0.29818517,  0.24949086,  0.19485225,  0.15278642,\n",
       "          0.13398252,  0.13737246,  0.15209071,  0.16372097,  0.16150291,\n",
       "          0.14304937,  0.11457718,  0.08693527,  0.06971818,  0.06653772,\n",
       "          0.0737545 ,  0.08306985,  0.08633735,  0.07984255,  0.06573208,\n",
       "          0.05003099,  0.03874047,  0.03455159,  0.03604118,  0.03936337,\n",
       "          0.04086202,  0.03884842],\n",
       "        [ 0.24903046,  0.2562405 ,  0.27396223,  0.27658606,  0.25463882,\n",
       "          0.21390289,  0.1691494 ,  0.13557445,  0.12161291,  0.12587275,\n",
       "          0.13894694,  0.14871112,  0.14632688,  0.13010524,  0.10560283,\n",
       "          0.08221076,  0.06815145,  0.06644912,  0.07381127,  0.08279873,\n",
       "          0.08597241,  0.07974294,  0.06590382,  0.05015947,  0.03864988,\n",
       "          0.03456987,  0.03681877,  0.04126684,  0.04355635,  0.04151615,\n",
       "          0.03581732,  0.02889732],\n",
       "        [ 0.23392968,  0.23507415,  0.21608245,  0.18220922,  0.14578485,\n",
       "          0.11916936,  0.10894935,  0.113573  ,  0.12498934,  0.13310601,\n",
       "          0.13075456,  0.11681941,  0.09621119,  0.07693502,  0.06586931,\n",
       "          0.06539696,  0.07249944,  0.08062691,  0.08325338,  0.07721663,\n",
       "          0.06412696,  0.04919754,  0.03823886,  0.0345293 ,  0.03728873,\n",
       "          0.0425172 ,  0.0455576 ,  0.04374536,  0.0375655 ,  0.02981604,\n",
       "          0.02360404,  0.02060907],\n",
       "        [ 0.18245973,  0.15440294,  0.12489792,  0.10395405,  0.0966496 ,\n",
       "          0.10134009,  0.11115883,  0.11777079,  0.11544895,  0.10356046,\n",
       "          0.08642253,  0.07078374,  0.06229353,  0.0627351 ,  0.06934001,\n",
       "          0.0764226 ,  0.07841022,  0.07267758,  0.06074577,  0.04728869,\n",
       "          0.03754405,  0.03454919,  0.03768143,  0.04324201,  0.04667738,\n",
       "          0.04511968,  0.03878287,  0.03048279,  0.0237225 ,  0.02064029,\n",
       "          0.02107657,  0.02313537]], dtype='>f4'),\n",
       " 'spec': array([[ 1.10708696,  1.46152834,  1.50655631,  1.50860595,  1.50927195,\n",
       "          1.50992726,  1.51058337,  1.51124086,  1.51190029,  1.51256221,\n",
       "          1.51322719,  1.51389579,  1.51456855,  1.51524577,  1.51592727,\n",
       "          1.51661232,  1.51729999,  1.51798932,  1.51867932,  1.51936904,\n",
       "          1.52005752,  1.52074502,  1.52148956,  1.52383764,  1.55036116,\n",
       "          1.78521301,  3.05399719,  7.17441746, 14.84320821, 21.47014431,\n",
       "         20.25745807, 12.43523509,  5.43346652,  2.37864977,  1.64019901,\n",
       "          1.53862754,  1.53124855,  1.531632  ,  1.53238964,  1.53317637,\n",
       "          1.53398013,  1.53479655,  1.53562123,  1.53644975,  1.53727769,\n",
       "          1.53810063,  1.53891413,  1.53971374,  1.540495  ,  1.54125351,\n",
       "          1.54198526,  1.54268798,  1.54336226,  1.54401042,  1.54463521,\n",
       "          1.54523943,  1.54582588,  1.54638611,  1.54551173,  1.50043367,\n",
       "          1.13714857],\n",
       "        [ 0.1694997 ,  0.22376615,  0.2306601 ,  0.23097388,  0.23107582,\n",
       "          0.23117612,  0.23127655,  0.23137719,  0.23147812,  0.23157944,\n",
       "          0.23168122,  0.23178356,  0.23188653,  0.23199019,  0.23209451,\n",
       "          0.23219936,  0.23230462,  0.23241013,  0.23251575,  0.23262132,\n",
       "          0.23272675,  0.23283542,  0.23307086,  0.23572735,  0.26320646,\n",
       "          0.42867464,  0.99764351,  2.09565536,  3.12288614,  3.11433688,\n",
       "          2.0871901 ,  1.01106459,  0.44912397,  0.27365024,  0.23893549,\n",
       "          0.23463583,  0.23439964,  0.23449739,  0.2346143 ,  0.23473473,\n",
       "          0.23485776,  0.23498273,  0.23510897,  0.23523579,  0.23536253,\n",
       "          0.23548849,  0.23561302,  0.23573541,  0.235855  ,  0.2359711 ,\n",
       "          0.23608311,  0.23619067,  0.23629388,  0.23639309,  0.23648872,\n",
       "          0.2365812 ,  0.23667096,  0.23675671,  0.23662281,  0.22972119,\n",
       "          0.17410107],\n",
       "        [ 1.10746665,  1.46202949,  1.50707277,  1.50912297,  1.50978906,\n",
       "          1.51044445,  1.51110065,  1.51175822,  1.51241773,  1.51307974,\n",
       "          1.51374481,  1.5144135 ,  1.51508634,  1.51576365,  1.51644524,\n",
       "          1.51713039,  1.51781815,  1.51850757,  1.51919767,  1.51988749,\n",
       "          1.52057615,  1.52127055,  1.5222843 ,  1.53048455,  1.62754591,\n",
       "          2.33530665,  5.30359033, 12.21703377, 20.11365053, 21.55560525,\n",
       "         15.05748261,  7.33412193,  3.11946331,  1.80485744,  1.55938702,\n",
       "          1.53254577,  1.53146639,  1.53214442,  1.53290974,  1.53369671,\n",
       "          1.5345006 ,  1.53531716,  1.53614198,  1.53697064,  1.53779873,\n",
       "          1.53862181,  1.53943544,  1.54023518,  1.54101657,  1.54177519,\n",
       "          1.54250705,  1.54320987,  1.54388424,  1.54453248,  1.54515734,\n",
       "          1.54576163,  1.54634813,  1.54690842,  1.5460336 ,  1.50094019,\n",
       "          1.13753239],\n",
       "        [ 0.1694113 ,  0.22364948,  0.23053986,  0.23085351,  0.23095543,\n",
       "          0.23105571,  0.23115612,  0.23125674,  0.23135765,  0.23145895,\n",
       "          0.23156071,  0.23166303,  0.23176598,  0.23186962,  0.23197391,\n",
       "          0.23207875,  0.23218398,  0.23228947,  0.23239506,  0.23250061,\n",
       "          0.23260598,  0.23271139,  0.23283089,  0.23325754,  0.2375128 ,\n",
       "          0.27081973,  0.44033426,  0.98945542,  2.05607953,  3.09744399,\n",
       "          3.13826235,  2.12725042,  1.02032331,  0.43764036,  0.26581992,\n",
       "          0.23703435,  0.23440857,  0.23437994,  0.23449323,  0.23461358,\n",
       "          0.23473658,  0.23486152,  0.23498772,  0.23511451,  0.23524121,\n",
       "          0.23536715,  0.23549164,  0.235614  ,  0.23573356,  0.23584964,\n",
       "          0.23596162,  0.23606916,  0.23617234,  0.23627153,  0.23636715,\n",
       "          0.23645961,  0.23654936,  0.23663509,  0.2365013 ,  0.22960325,\n",
       "          0.1740117 ],\n",
       "        [ 0.68897006,  0.90954845,  0.93757053,  0.93884603,  0.93926046,\n",
       "          0.93966823,  0.9400765 ,  0.94048563,  0.94089596,  0.94130785,\n",
       "          0.94172165,  0.94213769,  0.94255632,  0.94297773,  0.9434018 ,\n",
       "          0.94382808,  0.94425599,  0.94468493,  0.9451143 ,  0.94554349,\n",
       "          0.94597191,  0.94640051,  0.94689852,  0.94920277,  0.97719702,\n",
       "          1.21280959,  2.39306343,  5.81440958, 11.08586722, 13.96601075,\n",
       "         11.21233231,  5.93744448,  2.4501324 ,  1.22963974,  0.98327097,\n",
       "          0.9543674 ,  0.95278659,  0.95317037,  0.95364566,  0.95413527,\n",
       "          0.95463543,  0.95514347,  0.95565664,  0.95617221,  0.95668742,\n",
       "          0.95719951,  0.95770573,  0.9582033 ,  0.95868946,  0.95916145,\n",
       "          0.95961679,  0.96005407,  0.96047365,  0.96087697,  0.96126575,\n",
       "          0.96164174,  0.96200665,  0.96235525,  0.96181106,  0.93375781,\n",
       "          0.70767628]]),\n",
       " 'fid_pars': array([-6.71143604e-02,  1.09752734e-01, -1.31538484e+00,  2.81750000e-01,\n",
       "        -2.16270000e+01,  4.82040000e+02,  1.55084500e+00,  4.05013500e+00]),\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TrainDataset(1, 5, 11, config.data['pars_dir'], config.data['data_dir'], config.data['data_stem'])\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d401a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ForkCNN(8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64175712",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec_stack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Eifler/kl-nn/cnn/modules/networks.py:116\u001b[0m, in \u001b[0;36mForkCNN.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[0;32m--> 116\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet34\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    119\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_layers(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n"
     ]
    }
   ],
   "source": [
    "model.forward(img, spec_stack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kl-nn",
   "language": "python",
   "name": "kl-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
