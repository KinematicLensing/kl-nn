{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748ac49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from astropy.io import fits\n",
    "\n",
    "from networks import ForkCNN\n",
    "from train import train_nn, prepare_dataloader, ddp_setup, load_model\n",
    "from dataset import FiberDataset\n",
    "import config\n",
    "\n",
    "fits_dir = '/xdisk/timeifler/wxs0703/kl_nn/train_data/'\n",
    "samp_dir = '/xdisk/timeifler/wxs0703/kl_nn/samples/samples.csv'\n",
    "fig_dir = '/xdisk/timeifler/wxs0703/kl_nn/figures/'\n",
    "model_dir = '/xdisk/timeifler/wxs0703/kl_nn/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827fe39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "save_every = 1\n",
    "nepochs = config.train['epoch_number']\n",
    "batch_size = config.train['batch_size']\n",
    "nfeatures = config.train['feature_number']\n",
    "f_valid = config.train['validation_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb680414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0205 16:04:40.525019 140101027350336 torch/multiprocessing/spawn.py:145] Terminating process 23600 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 75, in _wrap\n    fn(i, *args)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 157, in train_nn\n    trainer.train(total_epochs)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 138, in train\n    train_loss, valid_loss = self._run_epoch(epoch)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 57, in _run_epoch\n    train_loss = self._trainFunc(epoch)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 66, in _trainFunc\n    for i, batch in enumerate(self.train_data):\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n    data = self._next_data()\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/dataset.py\", line 50, in __getitem__\n    with fits.open(join(self.data_dir, self.data_stem + f'{index}.fits')) as hdu:\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py\", line 222, in fitsopen\n    return HDUList.fromfile(\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py\", line 486, in fromfile\n    return cls._readfrom(\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py\", line 1169, in _readfrom\n    fileobj = _File(\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/file.py\", line 218, in __init__\n    self._open_filename(fileobj, mode, overwrite)\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/file.py\", line 641, in _open_filename\n    self._file = open(self.name, IO_FITS_MODES[mode])\nFileNotFoundError: [Errno 2] No such file or directory: '/xdisk/timeifler/wxs0703/kl_nn/test_data/training_44.fits'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_nn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:281\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    275\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:237\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:188\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    186\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    187\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 75, in _wrap\n    fn(i, *args)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 157, in train_nn\n    trainer.train(total_epochs)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 138, in train\n    train_loss, valid_loss = self._run_epoch(epoch)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 57, in _run_epoch\n    train_loss = self._trainFunc(epoch)\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/train.py\", line 66, in _trainFunc\n    for i, batch in enumerate(self.train_data):\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n    data = self._next_data()\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/u2/wxs0703/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/u2/wxs0703/Eifler/kl-nn/cnn/modules/dataset.py\", line 50, in __getitem__\n    with fits.open(join(self.data_dir, self.data_stem + f'{index}.fits')) as hdu:\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py\", line 222, in fitsopen\n    return HDUList.fromfile(\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py\", line 486, in fromfile\n    return cls._readfrom(\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py\", line 1169, in _readfrom\n    fileobj = _File(\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/file.py\", line 218, in __init__\n    self._open_filename(fileobj, mode, overwrite)\n  File \"/home/u2/wxs0703/.conda/envs/kl-nn/lib/python3.9/site-packages/astropy/io/fits/file.py\", line 641, in _open_filename\n    self._file = open(self.name, IO_FITS_MODES[mode])\nFileNotFoundError: [Errno 2] No such file or directory: '/xdisk/timeifler/wxs0703/kl_nn/test_data/training_44.fits'\n"
     ]
    }
   ],
   "source": [
    "mp.spawn(train_nn, args=(world_size, save_every, nepochs, batch_size, nfeatures, f_valid), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3418f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = join(model_dir, 'test_model19')\n",
    "model = load_model(path=model_file,strict=True, assign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86052b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kl-nn",
   "language": "python",
   "name": "kl-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
