{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4becae",
   "metadata": {},
   "source": [
    "### Train model in notebook (inefficient, for testing and debug only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6385cb45-c787-46e9-b3df-152ec3cc6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359b541-f580-4880-84a9-17f02bb9e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "#os.environ['NCCL_DEBUG_SUBSYS'] = 'ALL'\n",
    "#os.environ['TORCH_DISTRIBUTED_DEBUG'] = 'INFO'\n",
    "os.environ['NCCL_IB_DISABLE'] = '1'\n",
    "os.environ['NCCL_SOCKET_IFNAME'] = 'enp2s0f1np1'\n",
    "os.environ['NCCL_P2P_DISABLE'] = '1'\n",
    "os.environ['NCCL_BLOCKING_WAIT'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748ac49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import join\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.multiprocessing as mp\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader\n",
    "from astropy.io import fits\n",
    "import pyxis.torch as pxt\n",
    "import normflows as nf\n",
    "\n",
    "from networks import *\n",
    "from train import *\n",
    "import config\n",
    "\n",
    "train_dir = '/ocean/projects/phy250048p/shared/datasets/small'\n",
    "test_dir = '/ocean/projects/phy250048p/shared/datasets/small'\n",
    "fig_dir = '/ocean/projects/phy250048p/shared/figures/'\n",
    "model_dir = '/ocean/projects/phy250048p/shared/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed2a39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827fe39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 1\n",
    "save_every = 1\n",
    "nepochs = config.train['epoch_number']\n",
    "batch_size = config.train['batch_size']\n",
    "nfeatures = config.train['feature_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5440465d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "torch.cuda.set_device(0)\n",
    "init_process_group(backend='nccl', rank=0, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1197220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pxt.TorchDataset(train_dir)\n",
    "valid_ds = pxt.TorchDataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6a1750",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        sampler=DistributedSampler(train_ds),\n",
    "    )\n",
    "valid_dl = DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        sampler=DistributedSampler(valid_ds),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2534f8-f19a-4252-b93c-b57b414aff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define flows\n",
    "K = 4\n",
    "\n",
    "latent_size = config.train['feature_number']\n",
    "hidden_units = 64\n",
    "num_blocks = 2\n",
    "context_size = 1024\n",
    "\n",
    "flows = []\n",
    "for i in range(K):\n",
    "    flows += [nf.flows.MaskedAffineAutoregressive(latent_size, hidden_units, \n",
    "                                                  context_features=context_size, \n",
    "                                                  num_blocks=num_blocks)]\n",
    "    flows += [nf.flows.LULinearPermute(latent_size)]\n",
    "\n",
    "# Set base distribution\n",
    "context_encoder = MLP([context_size, 128, 64, latent_size*2],)\n",
    "q0 = nf.distributions.base.ConditionalDiagGaussian(latent_size, context_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d74cc7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForkCNN(\n",
       "  (cnn_spec): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU(inplace=True)\n",
       "    (31): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(256, 512, kernel_size=(3, 4), stride=(1, 1), bias=False)\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "  )\n",
       "  (flow): ConditionalNormalizingFlow(\n",
       "    (q0): ConditionalDiagGaussian(\n",
       "      (context_encoder): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          (1): LeakyReLU(negative_slope=0.0)\n",
       "          (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (3): LeakyReLU(negative_slope=0.0)\n",
       "          (4): Linear(in_features=64, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (flows): ModuleList(\n",
       "      (0): MaskedAffineAutoregressive(\n",
       "        (autoregressive_net): MADE(\n",
       "          (preprocessing): Identity()\n",
       "          (initial_layer): MaskedLinear(in_features=2, out_features=64, bias=True)\n",
       "          (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x MaskedResidualBlock(\n",
       "              (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x MaskedLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): MaskedLinear(in_features=64, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): LULinearPermute(\n",
       "        (permutation): _RandomPermutation()\n",
       "        (linear): _LULinear()\n",
       "      )\n",
       "      (2): MaskedAffineAutoregressive(\n",
       "        (autoregressive_net): MADE(\n",
       "          (preprocessing): Identity()\n",
       "          (initial_layer): MaskedLinear(in_features=2, out_features=64, bias=True)\n",
       "          (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x MaskedResidualBlock(\n",
       "              (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x MaskedLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): MaskedLinear(in_features=64, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): LULinearPermute(\n",
       "        (permutation): _RandomPermutation()\n",
       "        (linear): _LULinear()\n",
       "      )\n",
       "      (4): MaskedAffineAutoregressive(\n",
       "        (autoregressive_net): MADE(\n",
       "          (preprocessing): Identity()\n",
       "          (initial_layer): MaskedLinear(in_features=2, out_features=64, bias=True)\n",
       "          (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x MaskedResidualBlock(\n",
       "              (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x MaskedLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): MaskedLinear(in_features=64, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): LULinearPermute(\n",
       "        (permutation): _RandomPermutation()\n",
       "        (linear): _LULinear()\n",
       "      )\n",
       "      (6): MaskedAffineAutoregressive(\n",
       "        (autoregressive_net): MADE(\n",
       "          (preprocessing): Identity()\n",
       "          (initial_layer): MaskedLinear(in_features=2, out_features=64, bias=True)\n",
       "          (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x MaskedResidualBlock(\n",
       "              (context_layer): Linear(in_features=1024, out_features=64, bias=True)\n",
       "              (linear_layers): ModuleList(\n",
       "                (0-1): 2 x MaskedLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_layer): MaskedLinear(in_features=64, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): LULinearPermute(\n",
       "        (permutation): _RandomPermutation()\n",
       "        (linear): _LULinear()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vit): VisionTransformer(\n",
       "    (patch_embed): PatchEmbedding(\n",
       "      (proj): Conv2d(1, 512, kernel_size=(6, 6), stride=(6, 6))\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ForkCNN(mode=1, base=q0, flows=flows)\n",
    "model.to(0)\n",
    "# model = DDP(model, device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e2ac93-0a17-4d3d-bcd6-f67a0324fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), \n",
    "#                       lr=config.train['initial_learning_rate'],\n",
    "#                       momentum=config.train['momentum'])\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=config.train['initial_learning_rate'], \n",
    "                        weight_decay=config.train['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be164fd2-2848-40e8-984c-d24851d07689",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CNNTrainer(world_size, model, nfeatures, train_ds, valid_ds, optimizer, 0, save_every, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03518ec8-d3e3-4b6a-bf2d-cda26483f3ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/xwang30/.conda/envs/kl-nn/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "[rank0]:[W1022 14:19:45.769164848 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kl-nn/arch/train.py:237\u001b[0m, in \u001b[0;36mCNNTrainer.train\u001b[0;34m(self, max_epochs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epochs):\n\u001b[0;32m--> 237\u001b[0m     train_loss, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(valid_loss)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_rank:\n",
      "File \u001b[0;32m~/kl-nn/arch/train.py:155\u001b[0m, in \u001b[0;36mCNNTrainer._run_epoch\u001b[0;34m(self, epoch, show_log)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_rank:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomized SNR and noise for epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[1;32m    157\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m~/kl-nn/arch/train.py:179\u001b[0m, in \u001b[0;36mCNNTrainer._trainFunc\u001b[0;34m(self, epoch, show_log)\u001b[0m\n\u001b[1;32m    176\u001b[0m fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfid_train[batch_ids]\n\u001b[1;32m    178\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_batch(img, spec, fid)\n\u001b[0;32m--> 179\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_log \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_rank \u001b[38;5;129;01mand\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e8774f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdestroy_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kl-nn/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:2114\u001b[0m, in \u001b[0;36mdestroy_process_group\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2112\u001b[0m     pg \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m-> 2114\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _world\u001b[38;5;241m.\u001b[39mpg_map\u001b[38;5;241m.\u001b[39mget(pg, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid process group specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb680414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Setup:Initializing\n",
      "INFO:Setup:[rank: 0] Successfully set up device\n",
      "INFO:Setup:Setting up for density estimation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Setup:[rank: 0] Successfully loaded training objects\n",
      "INFO:Setup:[rank: 0] Successfully initialized Trainer\n",
      "/jet/home/xwang30/.conda/envs/kl-nn/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "INFO:Trainer:Setting up tensors on GPU\n",
      "INFO:Trainer:Uploading training set to GPU...\n",
      "INFO:Trainer:10% complete\n",
      "INFO:Trainer:20% complete\n",
      "INFO:Trainer:30% complete\n",
      "INFO:Trainer:40% complete\n",
      "INFO:Trainer:50% complete\n",
      "INFO:Trainer:60% complete\n",
      "INFO:Trainer:70% complete\n",
      "INFO:Trainer:80% complete\n",
      "INFO:Trainer:90% complete\n",
      "INFO:Trainer:Uploading validation set to GPU...\n",
      "INFO:Trainer:10% complete\n",
      "INFO:Trainer:20% complete\n",
      "INFO:Trainer:30% complete\n",
      "INFO:Trainer:40% complete\n",
      "INFO:Trainer:50% complete\n",
      "INFO:Trainer:60% complete\n",
      "INFO:Trainer:70% complete\n",
      "INFO:Trainer:80% complete\n",
      "INFO:Trainer:90% complete\n",
      "INFO:Trainer:Training start\n",
      "INFO:Trainer:Starting epoch 0\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 0\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 1 Loss: 1.3587103580317554 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 1 Loss: 1.3734562430985249 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 1\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 1\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 2 Loss: 1.3449604136374085 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 2 Loss: 1.3366643398499314 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 2\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 2\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 3 Loss: 1.3250654658753136 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 3 Loss: 1.3272117472769691 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 3\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 3\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 4 Loss: 1.3309767908377073 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 4 Loss: 1.3580796829401314 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 4\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 4\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 5 Loss: 1.333678969446548 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 5 Loss: 1.322982030089803 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 5\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 5\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 6 Loss: 1.3290732985720897 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 6 Loss: 1.3466590805634768 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 6\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 6\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 7 Loss: 1.3380441338675921 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 7 Loss: 1.3489555119763577 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 7\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 7\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 8 Loss: 1.3275321274441967 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 8 Loss: 1.3206341039160554 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 8\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 8\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 9 Loss: 1.32768035311895 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 9 Loss: 1.3201384751338578 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 9\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 9\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 10 Loss: 1.3309539756820998 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 10 Loss: 1.3241785003936766 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 10\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 10\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 11 Loss: 1.328980136008171 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 11 Loss: 1.3220913356034287 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 11\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 12 Loss: 1.3252362625440557 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 12 Loss: 1.3263093825950278 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 12\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 12\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 13 Loss: 1.3285216719712127 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 13 Loss: 1.3434578178699053 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 13\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 13\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 14 Loss: 1.3308002634583658 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 14 Loss: 1.3428930135855819 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.1]\n",
      "INFO:Trainer:Starting epoch 14\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 14\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 15 Loss: 1.3277334152088025 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 15 Loss: 1.3238193632113366 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 15\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 15\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 16 Loss: 1.3232436712615643 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 16 Loss: 1.3186696810014509 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 16\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 16\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 17 Loss: 1.3222122222168728 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 17 Loss: 1.3217295970261955 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 17\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 17\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 18 Loss: 1.3209709719515825 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 18 Loss: 1.3334658140685802 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 18\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 18\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 19 Loss: 1.3216786673908179 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 19 Loss: 1.3215060736047177 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 19\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 19\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 20 Loss: 1.3233418408696118 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 20 Loss: 1.317254790355481 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 20\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 20\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 21 Loss: 1.3237075593176755 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 21 Loss: 1.3325656125553098 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 21\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 21\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 22 Loss: 1.3253407247173803 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 22 Loss: 1.3219437723328862 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 22\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 22\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 23 Loss: 1.3236151791034498 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 23 Loss: 1.320537115549696 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 23\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 23\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 24 Loss: 1.3244958179230726 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 24 Loss: 1.3208267181162636 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 24\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 24\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 25 Loss: 1.3242046497235682 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 25 Loss: 1.3176547722868683 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.05]\n",
      "INFO:Trainer:Starting epoch 25\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 25\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 26 Loss: 1.3222267927274238 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 26 Loss: 1.3229978022387725 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.025]\n",
      "INFO:Trainer:Starting epoch 26\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 26\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 27 Loss: 1.3198220085664647 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 27 Loss: 1.3186325992738082 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.025]\n",
      "INFO:Trainer:Starting epoch 27\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 27\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 28 Loss: 1.3191940820925294 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 28 Loss: 1.3176424894606151 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.025]\n",
      "INFO:Trainer:Starting epoch 28\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 28\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 29 Loss: 1.3196026689570073 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 29 Loss: 1.3189068709987646 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.025]\n",
      "INFO:Trainer:Starting epoch 29\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 29\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 30 Loss: 1.319363171277314 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 30 Loss: 1.3209335211934654 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.025]\n",
      "INFO:Trainer:Starting epoch 30\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 30\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 31 Loss: 1.3200061406549037 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 31 Loss: 1.317849880300766 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.025]\n",
      "INFO:Trainer:Starting epoch 31\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 31\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 32 Loss: 1.3193350967415842 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 32 Loss: 1.318432472745647 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.0125]\n",
      "INFO:Trainer:Starting epoch 32\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 32\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 33 Loss: 1.3186723758577454 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 33 Loss: 1.3185132564454012 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.0125]\n",
      "INFO:Trainer:Starting epoch 33\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 33\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 34 Loss: 1.3187218541038936 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 34 Loss: 1.3182411911726353 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.0125]\n",
      "INFO:Trainer:Starting epoch 34\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 34\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 35 Loss: 1.318219052229107 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 35 Loss: 1.3179234535922135 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.0125]\n",
      "INFO:Trainer:Starting epoch 35\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 35\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 36 Loss: 1.3181944675870034 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 36 Loss: 1.3234005631265628 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.0125]\n",
      "INFO:Trainer:Starting epoch 36\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 36\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 37 Loss: 1.3186455310102283 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 37 Loss: 1.3185235701426303 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.0125]\n",
      "INFO:Trainer:Starting epoch 37\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 37\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 38 Loss: 1.3179190652885564 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 38 Loss: 1.3182745166736372 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.00625]\n",
      "INFO:Trainer:Starting epoch 38\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 38\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 39 Loss: 1.3179041893595842 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 39 Loss: 1.3171142888114669 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.00625]\n",
      "INFO:Trainer:Starting epoch 39\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 39\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 40 Loss: 1.3178673072582459 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 40 Loss: 1.318359458640767 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.00625]\n",
      "INFO:Trainer:Starting epoch 40\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 40\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 41 Loss: 1.3176996653979136 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 41 Loss: 1.3174588649053804 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.00625]\n",
      "INFO:Trainer:Starting epoch 41\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 41\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 42 Loss: 1.317684903696715 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 42 Loss: 1.3176210407197233 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.00625]\n",
      "INFO:Trainer:Starting epoch 42\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 42\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 43 Loss: 1.317814255428977 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 43 Loss: 1.3174194814952875 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.00625]\n",
      "INFO:Trainer:Starting epoch 43\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 43\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 44 Loss: 1.3179149397361232 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 44 Loss: 1.3171435614663936 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.00625]\n",
      "INFO:Trainer:Starting epoch 44\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 44\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 45 Loss: 1.3178041460488432 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 45 Loss: 1.3183627418757644 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.003125]\n",
      "INFO:Trainer:Starting epoch 45\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 45\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 46 Loss: 1.3173462166874519 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 46 Loss: 1.3190573704738875 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.003125]\n",
      "INFO:Trainer:Starting epoch 46\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 46\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 47 Loss: 1.3177025685039765 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 47 Loss: 1.3172853906351147 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.003125]\n",
      "INFO:Trainer:Starting epoch 47\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 47\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 48 Loss: 1.3171814779232194 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 48 Loss: 1.317561741943923 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.003125]\n",
      "INFO:Trainer:Starting epoch 48\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 48\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 49 Loss: 1.317186596780741 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 49 Loss: 1.317370565144 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.003125]\n",
      "INFO:Trainer:Starting epoch 49\n",
      "INFO:Trainer:Randomized SNR and noise for epoch 49\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[TRAIN] Epoch: 50 Loss: 1.3171196527530924 Time: 0:11\n",
      "INFO:Trainer:Batch 0 complete\n",
      "INFO:Trainer:[VALID] Epoch: 50 Loss: 1.3178020803805355 Time: 0:4\n",
      "INFO:Trainer:Current LR is [0.003125]\n"
     ]
    }
   ],
   "source": [
    "mp.spawn(train_nn, args=(world_size, ForkCNN, CNNTrainer), nprocs=world_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kl-nn",
   "language": "python",
   "name": "kl-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
